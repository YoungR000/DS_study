{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "import os \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import timm\n",
    "\n",
    "import random\n",
    "\n",
    "#from PIL import image\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('mnist/train.csv')\n",
    "test = pd.read_csv('mnist/test.csv')\n",
    "submission = pd.read_csv('mnist/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>label</th>\n",
       "      <th>px1</th>\n",
       "      <th>px2</th>\n",
       "      <th>px3</th>\n",
       "      <th>px4</th>\n",
       "      <th>px5</th>\n",
       "      <th>px6</th>\n",
       "      <th>px7</th>\n",
       "      <th>px8</th>\n",
       "      <th>...</th>\n",
       "      <th>px775</th>\n",
       "      <th>px776</th>\n",
       "      <th>px777</th>\n",
       "      <th>px778</th>\n",
       "      <th>px779</th>\n",
       "      <th>px780</th>\n",
       "      <th>px781</th>\n",
       "      <th>px782</th>\n",
       "      <th>px783</th>\n",
       "      <th>px784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>59995</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>59996</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>59997</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>59998</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>59999</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows × 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  label  px1  px2  px3  px4  px5  px6  px7  px8  ...  px775  \\\n",
       "0          0      5    0    0    0    0    0    0    0    0  ...      0   \n",
       "1          1      0    0    0    0    0    0    0    0    0  ...      0   \n",
       "2          2      4    0    0    0    0    0    0    0    0  ...      0   \n",
       "3          3      1    0    0    0    0    0    0    0    0  ...      0   \n",
       "4          4      9    0    0    0    0    0    0    0    0  ...      0   \n",
       "...      ...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   \n",
       "59995  59995      8    0    0    0    0    0    0    0    0  ...      0   \n",
       "59996  59996      3    0    0    0    0    0    0    0    0  ...      0   \n",
       "59997  59997      5    0    0    0    0    0    0    0    0  ...      0   \n",
       "59998  59998      6    0    0    0    0    0    0    0    0  ...      0   \n",
       "59999  59999      8    0    0    0    0    0    0    0    0  ...      0   \n",
       "\n",
       "       px776  px777  px778  px779  px780  px781  px782  px783  px784  \n",
       "0          0      0      0      0      0      0      0      0      0  \n",
       "1          0      0      0      0      0      0      0      0      0  \n",
       "2          0      0      0      0      0      0      0      0      0  \n",
       "3          0      0      0      0      0      0      0      0      0  \n",
       "4          0      0      0      0      0      0      0      0      0  \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...  \n",
       "59995      0      0      0      0      0      0      0      0      0  \n",
       "59996      0      0      0      0      0      0      0      0      0  \n",
       "59997      0      0      0      0      0      0      0      0      0  \n",
       "59998      0      0      0      0      0      0      0      0      0  \n",
       "59999      0      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[60000 rows x 786 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['index', 'label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_0 = train_df.loc[0].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_0 = np.reshape(try_0, (28,28,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_0 = try_0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 1), <f8",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2750\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2751\u001b[1;33m             \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2752\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: ((1, 1, 1), '<f8')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-fcd9b817ad53>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtry_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   2751\u001b[0m             \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrawmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_fromarray_typemap\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtypekey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2752\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2753\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cannot handle this data type: %s, %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtypekey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2754\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2755\u001b[0m         \u001b[0mrawmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 1), <f8"
     ]
    }
   ],
   "source": [
    "Image.fromarray(try_0).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# seed, loss func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed) :\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "def NMAE(true, pred) : \n",
    "    mae = np.mean(np.abs(true-pred))\n",
    "    score = mae/np.mean(np.abs(true))\n",
    "    return score\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128\n",
    "TEST_SIZE = 0.2\n",
    "N_EPOCH = 3\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "MODEL_NAME = 'densenet121'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_dataset(Dataset) :\n",
    "    def __init__(self, train_df, transform=None ) :\n",
    "        super(train_dataset).__init__()\n",
    "        self.train_df = train_df\n",
    "        self.transform = transform \n",
    "        \n",
    "    def __len__(self) : \n",
    "        return len(self.train_df)\n",
    "    \n",
    "    def __getitem__(self, idx) : \n",
    "        img = np.array(Image.open(self.train_df['image_path'][idx]))\n",
    "        \n",
    "        if self.transform : \n",
    "            img = self.transform(image=img)['image']\n",
    "        \n",
    "        weight = self.train_df['target'][idx]\n",
    "        weight = torch.tensor(weight, dtype=torch.float32)\n",
    "        \n",
    "        return img, weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_dataset(Dataset) : \n",
    "    def __init__(self, test_imgs, transform =None) :\n",
    "        super(test_dataset).__init__() \n",
    "        self.test_imgs = test_imgs\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__() :\n",
    "        return len(self.test_imgs)\n",
    "    \n",
    "    def __getitem__(self, idx) :  \n",
    "        img = np.array(Image.open(self.test_imgs[idx]))\n",
    "        \n",
    "        if self.transform : \n",
    "            img = self.transform(image=img)['image']\n",
    "            \n",
    "        return img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader, transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-06f323d87814>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_loadr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchsize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m img_transform = A.Compose([\n\u001b[0;32m      5\u001b[0m     \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoader(train_dataset(), batch_size = BATCH_SIZE, shuffle=True)\n",
    "val_loadr = DataLoader(train_dataset(), batch_size = BATCH_SIZE, shuffle=False)\n",
    "\n",
    "img_transform = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    A.Normalize(mean=(0.5,0.5,0.5), std=(0.5,0.5,0.5)),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained \n",
    "class ConvNet(nn.Module) : \n",
    "    def __init__(self, model_name, pretrained=True) : \n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv = timm.create_model(model_name, pretrained=pretrained) # 전이학습 모델 불러오고, \n",
    "        self.fc1 = nn.Linear(1000, 256)  # fc \n",
    "        self.relu = nn.ReLU() # activation\n",
    "        self.fc2 = nn.Linear(256,1) # fc  to 1 \n",
    "        \n",
    "        \n",
    "    def forward(self, inputs) : \n",
    "        X = self.conv(inputs)\n",
    "        X = self.fc1(X)\n",
    "        X = self.relu(X)\n",
    "        outputs = self.fc2(X)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 직접 model 구성\n",
    "\n",
    "class ConvNet(nn.Module) : \n",
    "    def __init__(self) : \n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer3 = torch.nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer4 = torch.nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.regressor = nn.Linear(3136,1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x) : \n",
    "        # (batch, 3, image_size, image_size)-> batch, 64, resize, resize)\n",
    "        # 128*128 -> 7*7\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        # 64*7*7 = 3136 \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        out = self.regressor(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss().to(device)  # Or L1loss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SIZE = 0.2\n",
    "N_EPOCH = 30 \n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "MODEL_NAME = 'resnet18'\n",
    "IMAGE_SIZE = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-9919e71259e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mavg_cosv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# dataframe 학습/평가로 나누고\n",
    "train_data, val_data = train_test_split(df, test_size = TEST_SIZE, random_state = SEED)\n",
    "train_data = train_data.reset_index(drop = True)\n",
    "val_data = val_data.reset_index(drop = True)\n",
    "\n",
    "# 각 데이터셋을 data loader로 읽어옴\n",
    "train_loader = DataLoader(train_dataset(train_data), shuffle=True, batch_size = BATCH_SIZE)\n",
    "val_loader = DataLoader(train_dataset(val_data), shuffle=True, batch_size = BATCH_SIZE)\n",
    "\n",
    "\n",
    "for epoch in range(N_EPOCH) : \n",
    "    avg_cosv = 0\n",
    "    \n",
    "    for data, target in train_loader : \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        # target = target[..., None].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(data) # 모델을 forward pass로 결과 저장 \n",
    "        cost = criterion(hypothesis, target) # output과 target loss계산\n",
    "        cost.backward() # backward해서 gradient계산\n",
    "        optimizer.step() # 모델 파라미터 갱신 \n",
    "        avg_cost += cost / len(train_loader)  # 평균 loss 계산 \n",
    "    print(f'[Epoch: {epoch+1:>4}] cost = {avg_cost:>.9}')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad() : # grad 해제 \n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for data, target in val_loader : \n",
    "            data = data.to(device)\n",
    "            target = target.to(device) \n",
    "            # target = target[..., None].to(device)\n",
    "            out = model(data)\n",
    "\n",
    "            preds = torch.max(out.data, 1)[1]\n",
    "            total += len(target) \n",
    "            correct += (preds==target).sum().item()\n",
    "\n",
    "            print('TEST ACCURACY :  ', 100.*correct/total, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-eee56b7965c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mval_loader\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'val_loader' is not defined"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad() : # grad 해제 \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for data, target in val_loader : \n",
    "        data = data.to(device)\n",
    "        target = target.to(device) \n",
    "        # target = target[..., None].to(device)\n",
    "        out = model(data)\n",
    "        \n",
    "        preds = torch.max(out.data, 1)[1]\n",
    "        total += len(target) \n",
    "        correct += (preds==target).sum().item()\n",
    "        \n",
    "        print('TEST ACCURACY :  ', 100.*correct/total, '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/validation def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader, vali_loader, scheduler, device):\n",
    "    model.to(device)\n",
    "\n",
    "    # Loss Function\n",
    "    criterion = nn.L1Loss().to(device)\n",
    "    best_mae = 9999\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        for img, label in tqdm(iter(train_loader)):\n",
    "            img, label = img.float().to(device), label.float().to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Data -> Model -> Output\n",
    "            logit = model(img)\n",
    "            # Calc loss\n",
    "            loss = criterion(logit.squeeze(1), label)\n",
    "\n",
    "            # backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss.append(loss.item())\n",
    "            \n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "            \n",
    "        # Evaluation Validation set\n",
    "        vali_mae = validation(model, vali_loader, criterion, device)\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}] Train MAE : [{np.mean(train_loss):.5f}] Validation MAE : [{vali_mae:.5f}]\\n')\n",
    "        \n",
    "        # Model Saved\n",
    "        if best_mae > vali_mae:\n",
    "            best_mae = vali_mae\n",
    "            torch.save(model.state_dict(), './best_model.pth')\n",
    "            print('Model Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, vali_loader, criterion, device):\n",
    "    model.eval() # Evaluation\n",
    "    vali_loss = []\n",
    "    with torch.no_grad():\n",
    "        for img, label in tqdm(iter(vali_loader)):\n",
    "            img, label = img.float().to(device), label.float().to(device)\n",
    "\n",
    "            logit = model(img)\n",
    "            loss = criterion(logit.squeeze(1), label)\n",
    "            \n",
    "            vali_loss.append(loss.item())\n",
    "\n",
    "    vali_mae_loss = np.mean(vali_loss)\n",
    "    return vali_mae_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNmodel = CNNRegressor().to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(params = CNNmodel.parameters(), lr = CFG[\"LEARNING_RATE\"])\n",
    "scheduler = None\n",
    "\n",
    "train(CNNmodel, optimizer, train_loader, vali_loader, scheduler, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, test_loader, device):\n",
    "    model.eval()\n",
    "    model_pred = []\n",
    "    with torch.no_grad():\n",
    "        for img in tqdm(iter(test_loader)):\n",
    "            img = img.float().to(device)\n",
    "\n",
    "            pred_logit = model(img)\n",
    "            pred_logit = pred_logit.squeeze(1).detach().cpu()\n",
    "\n",
    "            model_pred.extend(pred_logit.tolist())\n",
    "    return model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(processed_test_imgs, None, train_mode=False, transforms=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)\n",
    "\n",
    "# Validation Score가 가장 뛰어난 모델을 불러옵니다.\n",
    "checkpoint = torch.load('./best_model.pth')\n",
    "CNNmodel = CNNRegressor().to(device)\n",
    "CNNmodel.load_state_dict(checkpoint)\n",
    "\n",
    "# Inference\n",
    "preds = predict(CNNmodel, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('./open/sample_submission.csv')\n",
    "submission['leaf_weight'] = preds\n",
    "submission.to_csv('./CNNsubmit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

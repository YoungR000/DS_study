{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from glob import glob\n",
    "import os \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import timm\n",
    "\n",
    "import random\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('mnist/train.csv')\n",
    "test = pd.read_csv('mnist/test.csv')\n",
    "submission = pd.read_csv('mnist/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed) :\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "\n",
    "def NMAE(true, pred) : \n",
    "    mae = np.mean(np.abs(true-pred))\n",
    "    score = mae/np.mean(np.abs(true))\n",
    "    return score\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 28\n",
    "TEST_SIZE = 0.2\n",
    "N_EPOCH = 5\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 32\n",
    "MODEL_NAME = 'densenet121'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train_dataset(Dataset) :\n",
    "    def __init__(self, train_df, transform=None ) :\n",
    "        super(train_dataset).__init__()\n",
    "        self.train_df = train_df.drop(['index', 'label'],1)\n",
    "        self.target = train_df.label\n",
    "        self.transform = transform \n",
    "        \n",
    "    def __len__(self) : \n",
    "        return len(self.train_df)\n",
    "    \n",
    "    def __getitem__(self, idx) : \n",
    "        img = self.train_df.to_numpy()[idx].reshape(28,28)\n",
    "        img = torch.tensor(img/255).view(1,28,28)\n",
    "        img = img.type(torch.float32)\n",
    "        \n",
    "        #if self.transform : \n",
    "        #    img = self.transform(image=img)['image']\n",
    "        \n",
    "        target = self.target[idx]\n",
    "        target = torch.tensor(target, dtype=torch.float32)\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test_dataset(Dataset) : \n",
    "    def __init__(self, test_imgs, transform =None) :\n",
    "        super(test_dataset).__init__() \n",
    "        self.test_imgs = test_imgs.drop(['index'], 1)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self) :\n",
    "        return len(self.test_imgs)\n",
    "    \n",
    "    def __getitem__(self, idx) :  \n",
    "        img = self.test_imgs.to_numpy()[idx].reshape(28,28)\n",
    "        img = torch.tensor(img/255).view(1,28,28)\n",
    "        img = img.type(torch.float32)        \n",
    "        #if self.transform : \n",
    "        #    img = self.transform(image=img)['image']\n",
    "            \n",
    "        return img\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_transform = A.Compose([\n",
    "    A.Resize(IMAGE_SIZE, IMAGE_SIZE), \n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset(train), batch_size = BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset(test), batch_size = BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module) : \n",
    "    def __init__(self) : \n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))      \n",
    "        \n",
    "        self.fc = nn.Linear(7*7*64,10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x) : \n",
    "        # (batch, 3, image_size, image_size)-> batch, 64, resize, resize)\n",
    "        # 128*128 -> 7*7\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        \n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        out = self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)    # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = 'MNIST_Classification_CNN_Model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(train, test_size = 0.2, random_state = SEED, stratify = train['label'])\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset(train_df), shuffle= True, batch_size = BATCH_SIZE)\n",
    "val_loader = DataLoader(train_dataset(val_df), shuffle= False, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=2, factor = 0.5, min_lr = 5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.0125698429\n",
      "val_accuracy improved 0.0000 to 0.9926\n",
      "[Epoch 1 / 5] cost = 0.0126, val_accuracy=0.9926\n",
      "[Epoch:    2] cost = 0.0106809167\n",
      "[Epoch 2 / 5] cost = 0.0107, val_accuracy=0.9926\n",
      "[Epoch:    3] cost = 0.00828756113\n",
      "[Epoch 3 / 5] cost = 0.0083, val_accuracy=0.9926\n",
      "[Epoch:    4] cost = 0.00633600075\n",
      "[Epoch 4 / 5] cost = 0.0063, val_accuracy=0.9926\n",
      "[Epoch:    5] cost = 0.0059860223\n",
      "[Epoch 5 / 5] cost = 0.0060, val_accuracy=0.9926\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'weights_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-caed55b6b8d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'[Epoch {epoch+1} / {N_EPOCH}] cost = {avg_cost:.4f}, val_accuracy={val_score:.4f}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weights_path' is not defined"
     ]
    }
   ],
   "source": [
    "val_score = 0\n",
    "\n",
    "for epoch in range(N_EPOCH):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for X, Y in train_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        Y = Y.type(torch.LongTensor)\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / len(train_loader)\n",
    "\n",
    "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad() :\n",
    "        preds = [] \n",
    "        val_loss = 0\n",
    "        for X, Y in val_loader : \n",
    "            Y = Y.type(torch.LongTensor)\n",
    "            X = X.to(device)\n",
    "            Y = Y.to(device)\n",
    "            hypothesis = model(X)\n",
    "            batch_cost = criterion(hypothesis, Y)\n",
    "            val_loss += batch_cost / len(val_loader)\n",
    "            \n",
    "            pred = hypothesis.cpu().numpy()\n",
    "            preds.append(np.argmax(pred,1))\n",
    "            \n",
    "        accuracy = accuracy_score(val_df.label, np.concatenate(preds))\n",
    "        \n",
    "        if val_score < accuracy : \n",
    "            print(f'val_accuracy improved {val_score:.4f} to {accuracy:.4f}')\n",
    "            val_score = accuracy \n",
    "            torch.save(model.state_dict(), weight_path)\n",
    "        print(f'[Epoch {epoch+1} / {N_EPOCH}] cost = {avg_cost:.4f}, val_accuracy={val_score:.4f}')\n",
    "        \n",
    "model.load_state_dict(torch.load(weights_path))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "model.eval()\n",
    "with torch.no_grad() : \n",
    "    \n",
    "    for X in tqdm(test_loader) : \n",
    "        X = X.to(device)\n",
    "        pred = model(X)\n",
    "        pred = pred.cpu().numpy()\n",
    "        preds.append(np.argmax(pred,1))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_array = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['label_pred'] = preds_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['result'] = submission['label'] - submission['label_pred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['result'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
